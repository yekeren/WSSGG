{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from modeling import trainer\n",
    "from modeling.utils import visualization\n",
    "from modeling.utils.box_ops import py_iou\n",
    "from protos import pipeline_pb2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "image_dir = \"vg-gt-cap/images\"\n",
    "model_dir = \"logs/base_phr_ite_seq/\"\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "with tf.io.gfile.GFile(os.path.join(model_dir, \"pipeline.pbtxt\"), 'r') as fp: \n",
    "  pipeline_proto = text_format.Merge(fp.read(), pipeline_pb2.Pipeline())\n",
    "batch_generator = trainer.predict(pipeline_proto, model_dir)\n",
    "\n",
    "\n",
    "def get_examples():\n",
    "  \"\"\"Returns a generator that yields a single example each time. \"\"\"\n",
    "  while True:\n",
    "    try:\n",
    "      i = next(example_id_generator)\n",
    "    except Exception as ex:\n",
    "      example = next(batch_generator)\n",
    "      example_id_generator = (i for i in range(len(example['id'])))\n",
    "      i = next(example_id_generator)\n",
    "    \n",
    "    image_id = example['id'][i]\n",
    "    num_relations = example['common_sense/prediction/num_relations'][i]\n",
    "    \n",
    "    (predicate_classes, subject_boxes, subject_classes, object_boxes, object_classes\n",
    "    ) = (example['common_sense/prediction/relation_class'][i][:num_relations],\n",
    "         example['common_sense/prediction/subject_box'][i][:num_relations],\n",
    "         example['common_sense/prediction/subject_class'][i][:num_relations],\n",
    "         example['common_sense/prediction/object_box'][i][:num_relations],\n",
    "         example['common_sense/prediction/object_class'][i][:num_relations])  \n",
    "    yield (image_id, predicate_classes, subject_boxes, subject_classes, object_boxes, object_classes)\n",
    "  \n",
    "\n",
    "example_generator = get_examples()\n",
    "\n",
    "\n",
    "def insert_entity(entity_boxes, entity_names, box, name):\n",
    "  \"\"\"Insert entities.\"\"\"\n",
    "  seq_id = 0\n",
    "  for i in range(len(entity_names)):\n",
    "    if name == entity_names[i].split(':')[0] and py_iou(box, entity_boxes[i]) > 0.5:\n",
    "      return i\n",
    "    if name == entity_names[i].split(':')[0]:\n",
    "      seq_id += 1\n",
    "  entity_names.append(name if seq_id == 0 else name + ':%i' % seq_id)\n",
    "  entity_boxes.append(box)\n",
    "  return len(entity_names) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0412 15:41:11.129142 139923417290560 model_fn.py:630] Estimator's model_fn (<function _create_model_fn.<locals>._model_fn at 0x7f4120d9fea0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint logs/base_phr_ite_seq/model.ckpt-200000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 15:41:11.575868 139923417290560 module_wrapper.py:139] From /afs/cs.pitt.edu/projects/kovashka/keren3/WSSGG/python/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W0412 15:41:11.578100 139923417290560 module_wrapper.py:139] From /afs/cs.pitt.edu/projects/kovashka/keren3/WSSGG/python/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(5):\n",
    "  (image_id, predicate_classes, \n",
    "   subject_boxes, subject_classes, object_boxes, object_classes) = next(example_generator)\n",
    "  print('Processing %i.' % image_id)\n",
    "    \n",
    "  plt.figure(figsize=(30, 10), dpi=50)\n",
    "\n",
    "  # Load original image.\n",
    "  image = np.array(Image.open(os.path.join(image_dir, '%i.jpg' % image_id)))\n",
    "\n",
    "  entity_names = []  # Name with sequenceId, e.g., horse, cat, person:0, person:1, person:2.\n",
    "  entity_boxes = []\n",
    "\n",
    "  g = nx.DiGraph()\n",
    "  for index, (sub, sub_box, pred, obj, obj_box) in enumerate(\n",
    "      zip(subject_classes, subject_boxes, predicate_classes, object_classes, object_boxes)):\n",
    "    if index >= 5: break\n",
    "    sub_id = insert_entity(entity_boxes, entity_names, sub_box, sub.decode('ascii'))\n",
    "    obj_id = insert_entity(entity_boxes, entity_names, obj_box, obj.decode('ascii'))\n",
    "    \n",
    "    g.add_edge(entity_names[sub_id], entity_names[obj_id], label=pred.decode('ascii'), weight=0)\n",
    "\n",
    "  # Show image with detected entities.\n",
    "  ax = plt.subplot(1, 2, 1)\n",
    "  image_with_detections = visualization.draw_bounding_box_py_func_fn(\n",
    "      image, len(entity_names), entity_boxes, entity_names, None, 2)\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')\n",
    "\n",
    "  # Show predicted scene graph.\n",
    "  ax = plt.subplot(1, 2, 2)\n",
    "  pos = nx.shell_layout(g)\n",
    "  nx.draw_networkx_nodes(g, pos, node_size=0, node_shape='o', node_color='#1f78b4')\n",
    "  nx.draw_networkx_labels(g, pos, font_size=30, font_family='sans-serif')\n",
    "  nx.draw_networkx_edges(g, pos, arrowsize=40, width=2, draw_networkx_edges=True, \n",
    "                         arrowstyle='->', connectionstyle='arc3, rad=0.1')\n",
    "  nx.draw_networkx_edge_labels(\n",
    "      g, pos, font_size=30, edge_labels=dict([((u, v), d['label']) for u, v, d in g.edges(data=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
